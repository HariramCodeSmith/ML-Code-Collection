{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V2ZRzYGsCSnt"
   },
   "source": [
    "\n",
    "### 1. Download the data from <a href='https://drive.google.com/file/d/15dCNcmKskcFVjs7R0ElQkR61Ex53uJpM/view?usp=sharing'>here</a>. You have to use data.csv file for this assignment\n",
    "### 2. Code the model to classify data like below image. You can use any number of units in your Dense layers.\n",
    "\n",
    "<img src='https://i.imgur.com/33ptOFy.png'>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg22rD7sDPDu"
   },
   "source": [
    "# <font color='red'> <b>3. Writing Callbacks </b> </font>\n",
    "## You have to implement the following callbacks\n",
    "-  Write your own callback function, that has to print the micro F1 score and AUC score after each epoch.Do not use tf.keras.metrics for calculating AUC and F1 score.\n",
    "\n",
    "- Save your model at every epoch if your validation accuracy is improved from previous epoch. \n",
    "\n",
    "- You have to decay learning based on below conditions \n",
    "        Cond1. If your validation accuracy at that epoch is less than previous epoch accuracy, you have to decrese the\n",
    "               learning rate by 10%. \n",
    "        Cond2. For every 3rd epoch, decay your learning rate by 5%.\n",
    "        \n",
    "- If you are getting any NaN values(either weigths or loss) while training, you have to terminate your training. \n",
    "\n",
    "- You have to stop the training if your validation accuracy is not increased in last 2 epochs.\n",
    "\n",
    "- Use tensorboard for every model and analyse your scalar plots and histograms. (you need to upload the screenshots and write the observations for each model for evaluation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xCL3OGS0DsUa"
   },
   "source": [
    "<pre>\n",
    "<b>Model-1</b>\n",
    "<pre>\n",
    "1. Use tanh as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use RandomUniform(0,1) as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ZaRHRdEHDzOM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense,Input,Activation\n",
    "from tensorflow.keras.models import Model\n",
    "import random as rn\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "CSw5K9mrDzRq"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "x = df[['f1','f2']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = tf.keras.utils.to_categorical(y_train, 2) \n",
    "Y_test = tf.keras.utils.to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score,auc,roc_curve\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    \n",
    "    if (epoch % 3 ==0):\n",
    "        print('entering scheduler',0.95 * lr)\n",
    "        return 0.95 * lr\n",
    "    else:\n",
    "        return lr \n",
    "        \n",
    "  \n",
    "class CustomFunction(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,validation_data):\n",
    "      self.x_test = validation_data[0]\n",
    "      self.y_test= validation_data[1]\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        ## on begin of training, we are creating a instance varible called history\n",
    "        ## it is a dict with keys [ val_acc]\n",
    "        self.history={'val_accuracy': []}\n",
    "        \n",
    "    def on_epoch_end(self,epoch,logs={},):\n",
    "        try:\n",
    "            loss = logs.get('loss')\n",
    "            if loss is not None:\n",
    "                if np.isnan(loss) or np.isinf(loss):\n",
    "                    print(\"Invalid loss and terminated at epoch {}\".format(epoch))\n",
    "                    self.model.stop_training = True\n",
    "            if logs.get('val_accuracy', -1) != -1:\n",
    "                self.history['val_accuracy'].append(logs.get('val_accuracy'))\n",
    "            if(epoch != 0 and self.history['val_accuracy'][epoch] > self.history['val_accuracy'][epoch-1]):\n",
    "                print('\\nVal Accuracy Improved\\n')\n",
    "                model_json = self.model.to_json()\n",
    "                with open(\"model_save/model-epoch{}-val_accuracy-{}.json\".format(epoch,logs.get('val_accuracy')), \"w\") as json_file:\n",
    "                    json_file.write(model_json)\n",
    "\n",
    "                # serialize weights to HDF5\n",
    "                model.save_weights(\"model_save/weights-epoch{}-val_accuracy-{}.hdf5\".format(epoch,logs.get('val_accuracy')))\n",
    "                print(\"Saved model to disk\")\n",
    "            elif(epoch != 0 and self.history['val_accuracy'][epoch] < self.history['val_accuracy'][epoch-1]):\n",
    "                self.model.optimizer.lr = self.model.optimizer.lr * 0.9\n",
    "                print('learning rate reduced')\n",
    "            y_pred= self.model.predict(self.x_test)    \n",
    "            y_label_pred=np.argmax(y_pred,axis=1)\n",
    "           \n",
    "            f1_s = f1_score(self.y_test,y_label_pred,average='micro')\n",
    "            fpr, tpr, thresholds = roc_curve(self.y_test,y_label_pred)\n",
    "            auc_score = auc(fpr, tpr)\n",
    "            #Ideally Micro and Macro F1 Score is same as there is no class imbalance\n",
    "            print('Micro F1 Score: ',f1_s)\n",
    "            print('AUC Score: ',auc_score)\n",
    "        except:\n",
    "            print('Exception')\n",
    "        \n",
    "        \n",
    "monitor_function =CustomFunction(validation_data=[X_test,y_test])  \n",
    "learningratescheduler = LearningRateScheduler(scheduler)\n",
    "earlystop = EarlyStopping(monitor='val_accuracy', patience=2, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(2,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=30))(input_layer)\n",
    "#Dense hidden layer\n",
    "layer2 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=30))(layer1)\n",
    "#Dense hidden layer\n",
    "layer3 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=30))(layer2)\n",
    "#Dense hidden layer\n",
    "layer4 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=30))(layer3)\n",
    "#Dense hidden layer\n",
    "layer5 = Dense(50,activation='tanh',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=30))(layer4)\n",
    "#output layer\n",
    "output = Dense(2,activation='softmax',kernel_initializer=tf.keras.initializers.RandomUniform(minval=0, maxval=1, seed=30))(layer5)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.experimental.SGD(momentum=0.6),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering scheduler 0.009499999787658453\n",
      "Epoch 1/10\n",
      "207/207 [==============================] - 0s 706us/steps: 0.7321 - accuracy: \n",
      "Micro F1 Score:  0.46424242424242423\n",
      "AUC Score:  0.46424242424242423\n",
      "670/670 [==============================] - 2s 2ms/step - loss: 0.7294 - accuracy: 0.5057 - val_loss: 0.7069 - val_accuracy: 0.4642 - lr: 0.0095\n",
      "Epoch 2/10\n",
      "622/670 [==========================>...] - ETA: 0s - loss: 0.7001 - accuracy: 0.5129\n",
      "Val Accuracy Improved\n",
      "\n",
      "Saved model to disk\n",
      "207/207 [==============================] - 0s 621us/step\n",
      "Micro F1 Score:  0.5037878787878788\n",
      "AUC Score:  0.5037878787878788\n",
      "670/670 [==============================] - 1s 2ms/step - loss: 0.7000 - accuracy: 0.5131 - val_loss: 0.6987 - val_accuracy: 0.5038 - lr: 0.0095\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 0s 613us/steps: 0.7006 - accuracy: \n",
      "Micro F1 Score:  0.5037878787878788\n",
      "AUC Score:  0.5037878787878788\n",
      "670/670 [==============================] - 1s 1ms/step - loss: 0.7004 - accuracy: 0.5049 - val_loss: 0.7118 - val_accuracy: 0.5038 - lr: 0.0095\n",
      "entering scheduler 0.009024999709799886\n",
      "Epoch 4/10\n",
      "207/207 [==============================] - 0s 762us/steps: 0.6999 - accuracy\n",
      "Micro F1 Score:  0.5037878787878788\n",
      "AUC Score:  0.5037878787878788\n",
      "670/670 [==============================] - 1s 2ms/step - loss: 0.6998 - accuracy: 0.5011 - val_loss: 0.7023 - val_accuracy: 0.5038 - lr: 0.0090\n",
      "Epoch 4: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88fac217c0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=10, validation_data=(X_test,Y_test), batch_size=20, callbacks=[monitor_function,learningratescheduler,earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0036787944117144234"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-1) * 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CRpsCx3NEAtx"
   },
   "source": [
    "<pre>\n",
    "<b>Model-2</b>\n",
    "<pre>\n",
    "1. Use relu as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use RandomUniform(0,1) as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "btKuy2SWEFZo"
   },
   "outputs": [],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(2,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(seed=30))(input_layer)\n",
    "#Dense hidden layer\n",
    "layer2 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(seed=30))(layer1)\n",
    "#Dense hidden layer\n",
    "layer3 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(seed=30))(layer2)\n",
    "#Dense hidden layer\n",
    "layer4 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(seed=30))(layer3)\n",
    "#Dense hidden layer\n",
    "layer5 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(seed=30))(layer4)\n",
    "#output layer\n",
    "output = Dense(2,activation='softmax',kernel_initializer=tf.keras.initializers.RandomUniform(seed=0))(layer5)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.experimental.SGD(momentum=0.6),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "h-3tV-KIEFc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering scheduler 0.009499999787658453\n",
      "Epoch 1/10\n",
      "207/207 [==============================] - 0s 680us/steps: 0.6934 - accuracy: 0\n",
      "Micro F1 Score:  0.5\n",
      "AUC Score:  0.5\n",
      "670/670 [==============================] - 2s 2ms/step - loss: 0.6934 - accuracy: 0.4904 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 0.0095\n",
      "Epoch 2/10\n",
      "207/207 [==============================] - 0s 624us/steps: 0.6933 - accuracy: \n",
      "Micro F1 Score:  0.5\n",
      "AUC Score:  0.5\n",
      "670/670 [==============================] - 1s 2ms/step - loss: 0.6933 - accuracy: 0.5015 - val_loss: 0.6932 - val_accuracy: 0.5000 - lr: 0.0095\n",
      "Epoch 3/10\n",
      "207/207 [==============================] - 0s 621us/steps: 0.6934 - accuracy: \n",
      "Micro F1 Score:  0.5\n",
      "AUC Score:  0.5\n",
      "670/670 [==============================] - 1s 1ms/step - loss: 0.6934 - accuracy: 0.4946 - val_loss: 0.6933 - val_accuracy: 0.5000 - lr: 0.0095\n",
      "Epoch 3: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88fae43910>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,Y_train,epochs=10, validation_data=(X_test,Y_test), batch_size=20, callbacks=[monitor_function,learningratescheduler,earlystop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1e2VaqfEEDE"
   },
   "source": [
    "<pre>\n",
    "<b>Model-3</b>\n",
    "<pre>\n",
    "1. Use relu as an activation for every layer except output layer.\n",
    "2. use SGD with momentum as optimizer.\n",
    "3. use he_uniform() as initilizer.\n",
    "3. Analyze your output and training process. \n",
    "</pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "N2M4q3LYEF_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entering scheduler 0.009499999787658453\n",
      "Epoch 1/10\n",
      "207/207 [==============================] - 0s 772us/steps: 0.6452 - accuracy:\n",
      "Micro F1 Score:  0.6666666666666666\n",
      "AUC Score:  0.6666666666666666\n",
      "670/670 [==============================] - 2s 2ms/step - loss: 0.6448 - accuracy: 0.6242 - val_loss: 0.6104 - val_accuracy: 0.6667 - lr: 0.0095\n",
      "Epoch 2/10\n",
      "631/670 [===========================>..] - ETA: 0s - loss: 0.6108 - accuracy: 0.6642learning rate reduced\n",
      "207/207 [==============================] - 0s 612us/step\n",
      "Micro F1 Score:  0.6656060606060606\n",
      "AUC Score:  0.6656060606060605\n",
      "670/670 [==============================] - 1s 2ms/step - loss: 0.6108 - accuracy: 0.6636 - val_loss: 0.6067 - val_accuracy: 0.6656 - lr: 0.0085\n",
      "Epoch 3/10\n",
      "662/670 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.6669learning rate reduced\n",
      "207/207 [==============================] - 0s 609us/step\n",
      "Micro F1 Score:  0.6615151515151515\n",
      "AUC Score:  0.6615151515151516\n",
      "670/670 [==============================] - 1s 2ms/step - loss: 0.6063 - accuracy: 0.6672 - val_loss: 0.6126 - val_accuracy: 0.6615 - lr: 0.0077\n",
      "Epoch 3: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f88fcd8cb50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Input layer\n",
    "input_layer = Input(shape=(2,))\n",
    "#Dense hidden layer\n",
    "layer1 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(input_layer)\n",
    "#Dense hidden layer\n",
    "layer2 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer1)\n",
    "#Dense hidden layer\n",
    "layer3 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer2)\n",
    "#Dense hidden layer\n",
    "layer4 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer3)\n",
    "#Dense hidden layer\n",
    "layer5 = Dense(50,activation='relu',kernel_initializer=tf.keras.initializers.he_uniform())(layer4)\n",
    "#output layer\n",
    "output = Dense(2,activation='softmax',kernel_initializer=tf.keras.initializers.he_uniform())(layer5)\n",
    "#Creating a model\n",
    "model = Model(inputs=input_layer,outputs=output)\n",
    "model.compile(optimizer=tf.keras.optimizers.experimental.SGD(momentum=0.6),\n",
    "              loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,Y_train,epochs=10, validation_data=(X_test,Y_test), batch_size=20, callbacks=[monitor_function,learningratescheduler,earlystop])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WOaQiRbZEGDU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w41Y3TFENCXk"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "<pre>\n",
    "<b>Model-4</b>\n",
    "<pre>\n",
    "1. Try with any values to get better accuracy/f1 score.  \n",
    "</pre>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4agdXzB-DqOj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP3-7U_4LhC6"
   },
   "source": [
    "# Note \n",
    "Make sure that you are plotting tensorboard plots either in your notebook or you can try to create a pdf file with all the tensorboard screenshots.Please write your analysis of tensorboard results for each model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VPci2vqWMN2I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Call_Backs_Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
